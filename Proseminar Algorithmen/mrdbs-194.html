

<HTML> <HEAD>
<TITLE>18.2.4	 Parallele Sortierung </TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">
<A NAME=HEADING194></A><A NAME=HEADING194-0></A><A NAME=MARKER-9-24></A>
<A HREF="mrdbs-195.html"><IMG ALIGN = BOTTOM SRC = "next.gif"></A> <A HREF="mrdbs-193.html"><IMG ALIGN = BOTTOM SRC = "prev.gif"></A> <A HREF="mrdbs-190.html"><IMG ALIGN = BOTTOM SRC = "up.gif"></A> <A HREF="index.html"><IMG ALIGN = BOTTOM SRC = "top.gif"></A> <A HREF="mrdbs-3.html"><IMG ALIGN = BOTTOM SRC = "content.gif"></A> <A HREF="mrdbs-227.html"><IMG ALIGN = BOTTOM SRC = "index.gif"></A><P>
18.2  Parallelisierung un&auml;rer relationaler Operatoren<P>
<H3>18.2.4  Parallele <A NAME=MARKER-2-25></A>Sortierung </H3>
 Die Sortierung stellt einen h&auml;ufig ben&ouml;tigten Operator dar. Sie wird nicht nur bei der sortierten Ausgabe von Ergebnismengen notwendig, sondern auch zur Realisierung anderer Funktionen wie Duplikat-Eliminierung oder Join-Berechnung (Sort-Merge-Join). Da die zu sortierenden Datenmengen meist nicht vollst&auml;ndig im Hauptspeicher gehalten werden k&ouml;nnen, sind f&uuml;r DBS interne Sortierverfahren (z.B. Quicksort) nicht ausreichend. Es werden deswegen externe Verfahren eingesetzt, bei denen Zwischenergebnisse innerhalb von tempor&auml;ren Dateien auf Externspeicher ausgelagert werden. Hierzu wird zun&auml;chst in einer <I>Sortierphase</I> die Eingabe in mehrere Teile oder L&auml;ufe (runs) zerlegt, die sortiert und in tempor&auml;ren Dateien gespeichert werden. Die einzelnen L&auml;ufe werden dann in einer <I>Mischphase</I> sukzessive zu gr&ouml;&szlig;eren, sortierten L&auml;ufen gemischt, bis schlie&szlig;lich ein einziger Lauf erzeugt ist, der die sortierte Ausgabemenge repr&auml;sentiert. <P>
 Da die Sortierung in vielen DBS die teuerste Operation &uuml;berhaupt ist, stellt sie einen besonders geeigneten Kandidaten zur Parallelisierung dar. Zur Nutzung von Datenparallelit&auml;t sollte dabei die Eingabe bereits &uuml;ber mehrere Partitionen/Rechner verteilt sein (multiple input). Ebenso ist nach <A HREF=mrdbs-226.html#MARKER-9-153>[LY89]</A> eine Partitionierung der sortierten Ausgabe (multiple output) sehr wichtig, um die Verz&ouml;gerung zur Erzeugung eines sequentiellen Ausgabestromes zu vermeiden. Ferner sollten die Sortier- und Mischphasen parallel abgewickelt werden. Zur Reduzierung des Kommunikationsaufwandes sollte dazu jedes Tupel h&ouml;chstens einmal &uuml;ber das Netzwerk verschickt werden <A HREF=mrdbs-226.html#MARKER-9-97>[Gra93]</A>. In der folgenden Diskussion unterstellen wir eine <A NAME=MARKER-2-26></A>Shared-Nothing-Architektur. Eine &Uuml;bertragung der Ans&auml;tze auf Shared-Disk und Shared-Everything ist jedoch leicht m&ouml;glich.<P>
 Ein einfacher Ansatz zur parallelen Sortierung einer partitionierten Relation sieht vor, die Partitionen an den Datenknoten parallel einzulesen und lokal zu sortieren. Danach werden die so erzeugten L&auml;ufe an einen einzigen <I>Mischknoten</I> geschickt, wo durch Mischen das sortierte Gesamtergebnis erzeugt wird. Dieser Ansatz hat jedoch den offensichtlichen Nachteil, da&szlig; nur die erste Phase parallel arbeitet, w&auml;hrend das Mischen sowie die Ergebnisausgabe sequentiell an einem Knoten erfolgen. Dieser Nachteil kann durch folgenden Ansatz behoben werden.<P>
 Dabei erfolgt zun&auml;chst wieder das parallele Einlesen und Sortieren der verschiedenen Partitionen der Relation, die dann jedoch unter mehrere Mischknoten aufgeteilt werden<A HREF="#FOOTNOTE-80">[80]</A>. Diese dynamische <A NAME="MARKER-2-1023"></A>Datenumverteilung durch Verschicken der Tupel wird &uuml;ber eine (dynamische) Bereichspartitionierung auf dem Sortierattribut gesteuert. Dabei wird f&uuml;r p Mischprozessoren der Wertebereich des Sortierattributs vollst&auml;ndig in p disjunkte Intervalle zerlegt, so da&szlig; etwa gleich viel Tupel pro Intervall entfallen. Ein Tupel, dessen Sortierattributwert dem i-ten Intervall angeh&ouml;rt, wird dann an den i-ten Mischknoten geschickt. Damit enth&auml;lt jeder Mischprozessor alle Tupel des ihm zugeordneten Wertebereichsintervalls. Die einzelnen Mischknoten mischen die bei ihnen eingehenden Tupelstr&ouml;me parallel und unterst&uuml;tzen eine partitionierte Ausgabe an den Benutzer. Dabei wird zun&auml;chst das sortierte Ergebnis des ersten Mischprozessors bereitgestellt, dann das des zweiten usw. Der Algorithmus, der parallel in allen Phasen arbeitet, ist in <A HREF=#MARKER-9-28>Abb. 18-1</A> veranschaulicht. Dabei wurde die Sortierung auf einem Namensattribut unterstellt. Nicht gezeigt sind Plattenzugriffe f&uuml;r tempor&auml;re Dateien, die sowohl an den Daten- als auch an den Mischknoten notwendig werden k&ouml;nnen.<P>
<CENTER>
Abb. 18-1:   <B><A NAME=MARKER-9-28></A>Dynamische, bereichsbasierte Datenumverteilung zur parallelen Sortierung<BR></B><IMG SRC="mrdbs-194-image-362.gif"><P>
</CENTER>
 In <A HREF=mrdbs-226.html#MARKER-9-153>[LY89]</A> wurde eine Verfeinerung dieses Ansatzes vorgestellt, bei dem zur Reduzierung des Kommunikationsaufwandes nicht die vollst&auml;ndigen Tupel zu den Mischknoten geschickt werden, sondern lediglich die Sortierschl&uuml;sselwerte sowie die Nummer des zugeh&ouml;rigen Datenknotens. Die Ergebnistupel werden dann von den Datenknoten bereitgestellt, wobei die von den Mischknoten ermittelte Sortierreihenfolge festlegt, von welchem Datenknoten das jeweils n&auml;chste Ergebnistupel zu verwenden ist. Zur Bestimmung der dynamischen Bereichsfragmentierung wurde ferner vorgesehen, da&szlig; jeder Datenknoten nach der lokalen Sortierung die bei ihm vorliegende Werteverteilung einem Koordinatorknoten mitteilt. Dieser bestimmt aus den lokalen Werteverteilungen eine globale Bereichsfragmentierung, die allen Datenknoten mitgeteilt und zum Verschicken der Daten (Sortierschl&uuml;ssel) zu den Mischknoten verwendet wird.<P>
 Die Beschreibung der parallelen Sortierung verdeutlicht, da&szlig; die sequentiellen Basisoperatoren f&uuml;r Sortieren und Mischen in den Daten- und Mischknoten weiterhin zur Anwendung kommen. Die Parallelisierung basiert zum einen auf der partitionierten Datenverteilung zum Lesen der Eingabedaten und zum anderen auf der dynamischen Datenumverteilung zur Parallelisierung des Mischvorgangs. Eine sehr &auml;hnliche Vorgehensweise kann auch zur Parallelisierung anderer Operatoren angewendet werden, insbesondere zur Join-Berechnung (s.u.). Damit ist es auch relativ einfach m&ouml;glich, aus einem sequentiellen einen parallelen Ausf&uuml;hrungsplan zu erzeugen. Im <A NAME=MARKER-9-7></A>Gamma-System gen&uuml;gten so im wesentlichen zwei zus&auml;tzliche Operatoren, Split und Merge, zur Realisierung der parallelen Query-Bearbeitung <A HREF=mrdbs-226.html#MARKER-9-65>[DG92]</A>. Die <A NAME=MARKER-2-30></A>Split-Operation realisiert die Aufteilung eines Datenstromes in mehrere Teilmengen, die verschiedenen Rechnern bzw. Prozessen zugeordnet werden, z.B. &uuml;ber eine Bereichs- oder Hash-Fragmentierung gesteuert. Die <A NAME=MARKER-2-31></A>Merge-Operation nimmt dagegen das Mischen mehrerer Datenstr&ouml;me vor, die z.B. durch zuvor ausgef&uuml;hrte Operatoren auf verschiedenen Partitionen einer Relation erzeugt werden.  Im <A NAME=MARKER-9-61></A>Volcano-System sind die Split- und Merge-Funktionen durch einen einzigen Operator, dem sogenannten <A NAME=MARKER-2-33></A>Exchange-Operator, realisiert <A HREF=mrdbs-226.html#MARKER-9-98>[Gra94]</A>.<A NAME=MARKER-2-34></A><P>
<HR>

<A NAME="FOOTNOTE-80">[80] Das Einlesen von Externspeicher entf&auml;llt, wenn die zu sortierenden Daten als Ausgabe zuvor ausgef&uuml;hrter Operatoren noch im Hauptspeicher vorliegen.
<!-- TOC -->
<HR>



<A HREF="mrdbs-195.html"><IMG ALIGN = BOTTOM SRC = "next.gif"></A> <A HREF="mrdbs-193.html"><IMG ALIGN = BOTTOM SRC = "prev.gif"></A> <A HREF="mrdbs-190.html"><IMG ALIGN = BOTTOM SRC = "up.gif"></A> <A HREF="index.html"><IMG ALIGN = BOTTOM SRC = "top.gif"></A> <A HREF="mrdbs-3.html"><IMG ALIGN = BOTTOM SRC = "content.gif"></A> <A HREF="mrdbs-227.html"><IMG ALIGN = BOTTOM SRC = "index.gif"></A>
<P>

</BODY>
